{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 87,599\n",
      "Validation set size: 10,570\n",
      "\n",
      "Sample context:\n",
      "Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
      "Sample question:\n",
      "To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
      "Sample answer:\n",
      "{'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the SQuAD dataset\n",
    "dataset = load_dataset(\"squad\")\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_data = dataset['train']\n",
    "validation_data = dataset['validation']\n",
    "\n",
    "print(f\"Training set size: {len(train_data):,}\")\n",
    "print(f\"Validation set size: {len(validation_data):,}\\n\")\n",
    "print(f\"Sample context:\\n{train_data[0]['context']}\")\n",
    "print(f\"Sample question:\\n{train_data[0]['question']}\")\n",
    "print(f\"Sample answer:\\n{train_data[0]['answers']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Heuristic QA System üõ†Ô∏è\n",
    "Understand the basic heuristic approach for simple question answering, including text similarity and search techniques.\n",
    "\n",
    "**Approach:** Given a question and a context, the system will split the context into sentences and measure the similarity between the question and each sentence. The sentence with the highest similarity score will be returned as the answer.\n",
    "\n",
    "1. **Context Extraction:** Extract relevant passages from the context using text similarity techniques.\n",
    "2. **Text Similarity:** Measure similarity between the question and sentences in the context.\n",
    "3. **Answer Extraction:** Identify the span of text that most likely contains the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n",
      "Question: To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?\n",
      "Predicted Answer: It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858\n",
      "Actual Answer: Saint Bernadette Soubirous\n"
     ]
    }
   ],
   "source": [
    "def find_answer_heuristic(context, question):\n",
    "    \"\"\"\n",
    "    Find the answer to a question in a context using a heuristic approach.\n",
    "    \"\"\"\n",
    "    # Tokenize context into sentences\n",
    "    sentences = context.split('.') # splits the context into sentences not words\n",
    "    \n",
    "    # Vectorize the question and sentences\n",
    "    vectorizer = TfidfVectorizer().fit(sentences + [question])\n",
    "    question_vec = vectorizer.transform([question])\n",
    "    sentences_vec = vectorizer.transform(sentences)\n",
    "    \n",
    "    # Calculate cosine similarity between question and each sentence\n",
    "    similarities = cosine_similarity(question_vec, sentences_vec).flatten()\n",
    "    \n",
    "    # Find the most similar sentence\n",
    "    most_similar_idx = similarities.argmax()\n",
    "    most_similar_sentence = sentences[most_similar_idx]\n",
    "    \n",
    "    return most_similar_sentence.strip()\n",
    "\n",
    "# Test the heuristic approach on a sample question\n",
    "sample_context = train_data[0]['context']\n",
    "sample_question = train_data[0]['question']\n",
    "sample_answer = train_data[0]['answers']['text'][0]\n",
    "\n",
    "predicted_answer = find_answer_heuristic(sample_context, sample_question)\n",
    "\n",
    "print(f\"Context: {sample_context}\")\n",
    "print(f\"Question: {sample_question}\")\n",
    "print(f\"Predicted Answer: {predicted_answer}\")\n",
    "print(f\"Actual Answer: {sample_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Evaluation üìä\n",
    "Evaluate the effectiveness of the heuristic QA system on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on 100 samples: 64.00%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_qa_system(validation_data, num_samples=100):\n",
    "    \"\"\"\n",
    "    Evaluate the QA system on the validation data.\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    for i in range(num_samples):\n",
    "        context = validation_data[i]['context']\n",
    "        question = validation_data[i]['question']\n",
    "        actual_answer = validation_data[i]['answers']['text'][0]\n",
    "        \n",
    "        predicted_answer = find_answer_heuristic(context, question)\n",
    "        \n",
    "        # Check if the actual answer is contained within the predicted answer\n",
    "        if actual_answer.lower() in predicted_answer.lower():\n",
    "            correct += 1\n",
    "    \n",
    "    accuracy = correct / num_samples\n",
    "    print(f\"Accuracy on {num_samples} samples: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Evaluate the system\n",
    "evaluate_qa_system(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test the QA System üß™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: My name is John. I live in Cairo, Egypt. I work as a software engineer.\n",
      "\n",
      "Question: Where do I live?\n",
      "- Predicted Answer: I live in Cairo, Egypt\n"
     ]
    }
   ],
   "source": [
    "sample_context = \"My name is John. I live in Cairo, Egypt. I work as a software engineer.\"\n",
    "sample_question = \"Where do I live?\"\n",
    "\n",
    "predicted_answer = find_answer_heuristic(sample_context, sample_question)\n",
    "\n",
    "print(f\"Context: {sample_context}\\n\")\n",
    "print(f\"Question: {sample_question}\")\n",
    "print(f\"- Predicted Answer: {predicted_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Analysis and Improvements üîç\n",
    "Analyze the performance of the heuristic QA system and suggest potential improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24‚Äì10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "Question: Which NFL team represented the AFC at Super Bowl 50?\n",
      "Predicted Answer: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season\n",
      "Actual Answer: Denver Broncos\n",
      "#Prediction failed for this example.#\n",
      "\n",
      "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24‚Äì10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "Question: Which NFL team represented the NFC at Super Bowl 50?\n",
      "Predicted Answer: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season\n",
      "Actual Answer: Carolina Panthers\n",
      "#Prediction failed for this example.#\n",
      "\n",
      "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24‚Äì10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "Question: Where did Super Bowl 50 take place?\n",
      "Predicted Answer: As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50\n",
      "Actual Answer: Santa Clara, California\n",
      "#Prediction failed for this example.#\n",
      "\n",
      "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24‚Äì10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "Question: Which NFL team won Super Bowl 50?\n",
      "Predicted Answer: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season\n",
      "Actual Answer: Denver Broncos\n",
      "#Prediction failed for this example.#\n",
      "\n",
      "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24‚Äì10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "Question: What color was used to emphasize the 50th anniversary of the Super Bowl?\n",
      "Predicted Answer: As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50\n",
      "Actual Answer: gold\n"
     ]
    }
   ],
   "source": [
    "# Analyze a few examples where the model fails\n",
    "for i in range(5):\n",
    "    context = validation_data[i]['context']\n",
    "    question = validation_data[i]['question']\n",
    "    actual_answer = validation_data[i]['answers']['text'][0]\n",
    "    \n",
    "    predicted_answer = find_answer_heuristic(context, question)\n",
    "    \n",
    "    print(f\"\\nContext: {context}\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Predicted Answer: {predicted_answer}\")\n",
    "    print(f\"Actual Answer: {actual_answer}\")\n",
    "    \n",
    "    if actual_answer.lower() not in predicted_answer.lower(): # Wrong answer (model failed)\n",
    "        print(\"#Prediction failed for this example.#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion üéØ\n",
    "In this notebook, we developed a simple Question Answering (QA) system using a heuristic approach based on text similarity. The system was tested on the SQuAD dataset and provided answers by identifying the most relevant sentences in the context.\n",
    "\n",
    "**Next steps** could involve exploring more advanced QA systems based on deep learning models like [BERT](../../../3.%20Advanced/bert/) or fine-tuning pre-trained models for QA tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
