{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package conll2002 to /home/omar/nltk_data...\n",
      "[nltk_data]   Package conll2002 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 6658\n",
      "Test set size: 1665\n",
      "Sample data:\n",
      " [('As√≠', 'RG', 'O'), ('lo', 'PP', 'O'), ('manifest√≥', 'VMI', 'O'), ('hoy', 'RG', 'O'), ('el', 'DA', 'O'), ('portavoz', 'NC', 'O'), ('del', 'SP', 'O'), ('Grupo', 'NC', 'B-ORG'), ('Parlamentario', 'AQ', 'I-ORG'), ('Socialista', 'AQ', 'I-ORG'), (',', 'Fc', 'O'), ('Jaime', 'VMI', 'B-PER'), ('Gonz√°lez', 'AQ', 'I-PER'), (',', 'Fc', 'O'), ('despu√©s', 'RG', 'O'), ('del', 'SP', 'O'), ('encuentro', 'NC', 'O'), ('que', 'PR', 'O'), ('mantuvieron', 'VMI', 'O'), ('hoy', 'RG', 'O'), ('en', 'SP', 'O'), ('Astorga', 'VMN', 'B-LOC'), ('una', 'DI', 'O'), ('treintena', 'NC', 'O'), ('de', 'SP', 'O'), ('representantes', 'NC', 'O'), ('del', 'SP', 'O'), ('PSOE', 'NC', 'B-ORG'), ('en', 'SP', 'O'), ('las', 'DA', 'O'), ('Cortes', 'NC', 'B-ORG'), (',', 'Fc', 'O'), ('para', 'SP', 'O'), ('analizar', 'VMN', 'O'), ('la', 'DA', 'O'), ('actualidad', 'NC', 'O'), ('pol√≠tica', 'AQ', 'O'), ('en', 'SP', 'O'), ('la', 'DA', 'O'), ('Autonom√≠a', 'NC', 'B-ORG'), ('.', 'Fp', 'O')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "# Download and load the dataset\n",
    "nltk.download('conll2002')\n",
    "dataset = nltk.corpus.conll2002.iob_sents('esp.train')\n",
    "\n",
    "# Convert dataset into train/test splits\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training set size:\", len(train_data))\n",
    "print(\"Test set size:\", len(test_data))\n",
    "print(\"Sample data:\\n\", train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature Extraction for CRFs üõ†Ô∏è\n",
    "Extract features from words in sentences to feed into the CRF model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample features:\n",
      " {'bias': 1.0, 'word.lower()': 'as√≠', 'word[-3:]': 'As√≠', 'word[-2:]': 's√≠', 'word.isupper()': False, 'word.istitle()': True, 'word.isdigit()': False, 'postag': 'RG', 'postag[:2]': 'RG', 'BOS': True, '+1:word.lower()': 'lo', '+1:postag': 'PP', '+1:postag[:2]': 'PP'}\n"
     ]
    }
   ],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]\n",
    "\n",
    "# Extract features and labels for train/test sets\n",
    "X_train = [sent2features(s) for s in train_data]\n",
    "y_train = [sent2labels(s) for s in train_data]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_data]\n",
    "y_test = [sent2labels(s) for s in test_data]\n",
    "\n",
    "print(\"Sample features:\\n\", X_train[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training the CRF Model üèãÔ∏è‚Äç‚ôÇÔ∏è\n",
    "Train a CRF model using the extracted features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully.\n"
     ]
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model trained successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Evaluation üìä\n",
    "Evaluate the performance of the CRF model using metrics like precision, recall, F1-score, and overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-ORG      0.860     0.866     0.863      1444\n",
      "       I-ORG      0.741     0.839     0.787       933\n",
      "       B-PER      0.877     0.918     0.897       768\n",
      "       I-PER      0.901     0.955     0.927       713\n",
      "       B-LOC      0.826     0.810     0.818       995\n",
      "      B-MISC      0.794     0.590     0.677       439\n",
      "      I-MISC      0.743     0.574     0.648       705\n",
      "       I-LOC      0.816     0.686     0.745       420\n",
      "\n",
      "   micro avg      0.826     0.807     0.816      6417\n",
      "   macro avg      0.820     0.780     0.795      6417\n",
      "weighted avg      0.824     0.807     0.812      6417\n",
      "\n",
      "Overall Accuracy: 0.9731709637522595\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O') # Remove 'O' label from evaluation\n",
    "\n",
    "print(\"Classification Report:\\n\")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=labels, digits=3\n",
    "))\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy = metrics.flat_accuracy_score(y_test, y_pred)\n",
    "print(\"Overall Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Analysis and Error Inspection üîç\n",
    "Analyze the model‚Äôs performance, focusing on areas where it may have misclassified entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "I-MISC -> I-MISC  6.187372\n",
      "B-ORG  -> I-ORG   5.530408\n",
      "B-PER  -> I-PER   5.527766\n",
      "I-ORG  -> I-ORG   5.368968\n",
      "B-LOC  -> I-LOC   5.051907\n",
      "I-LOC  -> I-LOC   4.919433\n",
      "B-MISC -> I-MISC  4.807263\n",
      "I-PER  -> I-PER   4.235491\n",
      "O      -> O       3.691834\n",
      "O      -> B-MISC  2.260971\n",
      "\n",
      "Top unlikely transitions:\n",
      "I-ORG  -> B-LOC   -3.044190\n",
      "B-ORG  -> B-ORG   -3.232873\n",
      "B-MISC -> B-MISC  -3.324286\n",
      "I-PER  -> B-ORG   -3.418804\n",
      "B-ORG  -> B-MISC  -3.576592\n",
      "B-PER  -> B-PER   -4.054614\n",
      "O      -> I-PER   -5.490260\n",
      "O      -> I-MISC  -5.520934\n",
      "O      -> I-LOC   -6.062081\n",
      "O      -> I-ORG   -6.212764\n",
      "\n",
      "Top positive features:\n",
      "B-ORG   8.867643 word.lower():efe-cantabria\n",
      "B-ORG   8.466314 word.lower():psoe-progresistas\n",
      "O       5.326065 BOS\n",
      "B-ORG   4.875931 word.lower():xfera\n",
      "I-LOC   4.673665 -1:word.lower():calle\n",
      "B-ORG   4.609254 word[-2:]:-e\n",
      "B-MISC  4.588559 word.lower():diversia\n",
      "B-LOC   4.557490 word.lower():l√≠bano\n",
      "B-ORG   4.531936 word.lower():telef√≥nica\n",
      "B-PER   4.350310 -1:word.lower():seg√∫n\n",
      "\n",
      "Top negative features:\n",
      "O       -2.455684 -1:word.lower():secci√≥n\n",
      "O       -2.664321 word[-2:]:nd\n",
      "O       -3.078815 word.lower():mas\n",
      "O       -3.122621 -1:word.lower():espa√±olas\n",
      "O       -3.148819 word[-3:]:LOS\n",
      "B-PER   -3.321737 -1:word.lower():del\n",
      "O       -3.765075 word[-2:]:om\n",
      "O       -4.107175 -1:word.lower():celebrar√°n\n",
      "O       -4.370299 word.isupper()\n",
      "O       -8.033770 word.istitle()\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(f\"{label_from:6} -> {label_to:7} {weight:.6f}\")\n",
    "\n",
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(f\"{label:7} {weight:.6f} {attr}\")\n",
    "\n",
    "# Most common transitions\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(10))\n",
    "\n",
    "# Least common transitions\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-10:])\n",
    "\n",
    "# Most important features\n",
    "print(\"\\nTop positive features:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(10))\n",
    "\n",
    "print(\"\\nTop negative features:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common()[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The CRF model is a powerful tool for named entity recognition tasks, as it can capture complex patterns in the data and make predictions based on these patterns. By extracting features from the text and training the model on labeled data, we can build a robust NER system that can identify entities in unstructured text data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
